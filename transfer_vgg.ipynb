{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YanghuiWu/MV-Hat/blob/main/transfer_vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_DdGGkYDXql",
        "outputId": "d9690ab4-ef38-40be-d39d-25c119e8f36d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/Hats/FinalData\n",
            "\u001b[0m\u001b[01;34mData_Full\u001b[0m/     HumanOnly.csv           vgg16_hats_only.pt\n",
            "Data_Full.csv  lenet_hats.pt           vgg16_hats.pt\n",
            "\u001b[01;34mHatsOnly\u001b[0m/      pytorch_dataset.py      vgg16_human_imagenet.pt\n",
            "HatsOnly.csv   ReadMe.txt              vgg16_human_only.pt\n",
            "\u001b[01;34mHumanOnly\u001b[0m/     vgg16_hats_imagenet.pt  vgg16_imagenet.pt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "%cd /content/gdrive/My Drive/Colab Notebooks/Hats/FinalData/\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "959GWP1VDJ-2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import ssl\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "#from pytorch_dataset import HatsDataset\n",
        "import torch.optim as optim\n",
        "\n",
        "# for pretrained model\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJjmixByD42m"
      },
      "outputs": [],
      "source": [
        "# for data prep\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from skimage import io\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-UC4HTUDx4d"
      },
      "outputs": [],
      "source": [
        "class HatsDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir,transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img_path = os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
        "        image = io.imread(img_path)\n",
        "        y_label = torch.tensor(int(self.annotations.iloc[index,1]))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return (image,y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVEjlIv0DJ-4"
      },
      "outputs": [],
      "source": [
        "in_channel = 3\n",
        "num_class = 15\n",
        "learning_rate = 1e-3\n",
        "batch_size = 16\n",
        "num_epochs = 50\n",
        "\n",
        "# Prepare Dataset\n",
        "# for transfer learning, images are resized to 224*224\n",
        "\n",
        "tf = transforms.Compose([transforms.ToPILImage(),transforms.Resize((224, 224)),transforms.ToTensor()])\n",
        "\n",
        "# tf = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1),\n",
        "#     transforms.RandomAffine(degrees=40, translate=None, scale=(1, 2), shear=15, resample=False, fillcolor=0),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "# ])\n",
        "\n",
        "\n",
        "\n",
        "mixset = HatsDataset(csv_file='Data_Full.csv', root_dir='Data_Full', transform = tf)  #8779\n",
        "\n",
        "hatset = HatsDataset(csv_file='HatsOnly.csv', root_dir='HatsOnly', transform = tf)  #7139\n",
        "humanset = HatsDataset(csv_file='HumanOnly.csv', root_dir='HumanOnly', transform = tf)\n",
        "\n",
        "# transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "hat_trainset, hat_testset = torch.utils.data.random_split(hatset, [int(0.8*len(hatset)), len(hatset) - int(0.8*len(hatset))])\n",
        "human_trainset, human_testset = torch.utils.data.random_split(humanset, [int(0.8*len(humanset)), len(humanset) - int(0.8*len(humanset))])\n",
        "\n",
        "mix_trainset = torch.utils.data.ConcatDataset([hat_trainset, human_trainset])\n",
        "mix_testset = torch.utils.data.ConcatDataset([hat_testset, human_testset])\n",
        "\n",
        "classes = ('baseballcap', 'BikeHelmet', 'BucketHat', 'CowboyHat',\n",
        "           'FeltHat', 'FireFighterHat', 'FlatCap', 'GraduationCap', 'Heaterhat', 'MilitaryHelmet',\n",
        "           'MotorCycle Helmet', 'Police Hat', 'SateftyHelmet', 'TopHat', 'beanie')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPZ3wfrb6XfD"
      },
      "outputs": [],
      "source": [
        "\n",
        "### ONLY CHANGE THIS\n",
        "trainset = hat_trainset\n",
        "testset = human_testset\n",
        "\n",
        "# 76 for mix-human\n",
        "# 88 for mix-hat\n",
        "\n",
        "# 79 for hat-mix\n",
        "# 38 for hat-human\n",
        "\n",
        "checkpoint = \"vgg16_imagenet.pt\"\n",
        "### TO TEST ON DIFFERENT DATASETS\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0G41c6tDJ-6"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# https://www.analyticsvidhya.com/blog/2021/06/transfer-learning-using-vgg16-in-pytorch/\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "dropout = 0.5\n",
        "num_classes = 15\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(512 * 7 * 7, 4096),\n",
        "    nn.ReLU(True),\n",
        "    nn.Dropout(p=dropout),\n",
        "    nn.Linear(4096, 4096),\n",
        "    nn.ReLU(True),\n",
        "    nn.Dropout(p=dropout),\n",
        "    nn.Linear(4096, num_classes),\n",
        ")\n",
        "\n",
        "model = model.to(device=device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr9uvp423KT1",
        "outputId": "cdf52b29-6718-4b4e-eb96-91f57acfb601"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [-1, 512, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
            "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [-1, 512, 14, 14]               0\n",
            "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 4096]      16,781,312\n",
            "             ReLU-37                 [-1, 4096]               0\n",
            "          Dropout-38                 [-1, 4096]               0\n",
            "           Linear-39                   [-1, 15]          61,455\n",
            "================================================================\n",
            "Total params: 134,321,999\n",
            "Trainable params: 134,321,999\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 218.77\n",
            "Params size (MB): 512.40\n",
            "Estimated Total Size (MB): 731.75\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5omeHcERDJ-7",
        "outputId": "ccc6bdc3-d976-4fa8-9fca-a138e0bade5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1 loss: 2.0554375822136715\n",
            "[Epoch: 2 loss: 0.9531180745914203\n",
            "[Epoch: 3 loss: 0.6272893630239476\n",
            "[Epoch: 4 loss: 0.4574914970943908\n",
            "[Epoch: 5 loss: 0.340241155193216\n",
            "[Epoch: 6 loss: 0.25932319522300523\n",
            "[Epoch: 7 loss: 0.19315721242524245\n",
            "[Epoch: 8 loss: 0.14210570184905238\n",
            "[Epoch: 9 loss: 0.10969857702518263\n",
            "[Epoch: 10 loss: 0.10016626412575903\n",
            "[Epoch: 11 loss: 0.08099243679039535\n",
            "[Epoch: 12 loss: 0.07249681496600091\n",
            "[Epoch: 13 loss: 0.06114565667767059\n",
            "[Epoch: 14 loss: 0.05068814926524777\n",
            "[Epoch: 15 loss: 0.04437023864875428\n",
            "[Epoch: 16 loss: 0.044431501681148795\n",
            "[Epoch: 17 loss: 0.050781275717025044\n",
            "[Epoch: 18 loss: 0.0388123886714362\n",
            "[Epoch: 19 loss: 0.043783141173924844\n",
            "[Epoch: 20 loss: 0.03645280269126236\n",
            "[Epoch: 21 loss: 0.03876287725536252\n",
            "[Epoch: 22 loss: 0.029378133393058677\n",
            "[Epoch: 23 loss: 0.027042617746146202\n",
            "[Epoch: 24 loss: 0.034566188970445694\n",
            "[Epoch: 25 loss: 0.029759868621851933\n",
            "[Epoch: 26 loss: 0.030091486664988485\n",
            "[Epoch: 27 loss: 0.025945377946180403\n",
            "[Epoch: 28 loss: 0.02929453775673095\n",
            "[Epoch: 29 loss: 0.027980289127146472\n",
            "[Epoch: 30 loss: 0.024521987162206285\n",
            "[Epoch: 31 loss: 0.022563644754349813\n",
            "[Epoch: 32 loss: 0.02390318479350147\n",
            "[Epoch: 33 loss: 0.02079657128488383\n",
            "[Epoch: 34 loss: 0.02148296196437692\n",
            "[Epoch: 35 loss: 0.01889156888592734\n",
            "[Epoch: 36 loss: 0.025260305256975413\n",
            "[Epoch: 37 loss: 0.020838315794964667\n",
            "[Epoch: 38 loss: 0.019539433522307057\n",
            "[Epoch: 39 loss: 0.016292112079660224\n",
            "[Epoch: 40 loss: 0.023097466497311675\n",
            "[Epoch: 41 loss: 0.018294398506418282\n",
            "[Epoch: 42 loss: 0.01661094336269147\n",
            "[Epoch: 43 loss: 0.014665958473410136\n",
            "[Epoch: 44 loss: 0.02165030618405591\n",
            "[Epoch: 45 loss: 0.016517377499468067\n",
            "[Epoch: 46 loss: 0.01741413755116198\n",
            "[Epoch: 47 loss: 0.019678649431663885\n",
            "[Epoch: 48 loss: 0.015721236569188782\n",
            "[Epoch: 49 loss: 0.016317296102492603\n",
            "[Epoch: 50 loss: 0.013793425555981108\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "model.train()\n",
        "losses = []\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for data in trainloader:\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)    \n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # print loss every epoch\n",
        "    print(f'[Epoch: {epoch + 1} loss: {running_loss / len(trainloader)}')\n",
        "    losses.append(running_loss / len(trainloader))\n",
        "    running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Q6eOwmvRDuAt",
        "outputId": "cdd38251-f2ab-4d30-c33a-321a1af8a15a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f255a2fab50>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "torch.save(model.state_dict(), checkpoint)\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzCcmILPDJ-8",
        "outputId": "563384be-1ebb-4369-c108-babb7db608f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the validation images: 38 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "model.eval() # Turn to evaluation mode to ignore dropout\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # images = images.to('cpu')\n",
        "        # labels = labels.to('cpu')\n",
        "        images = images.to(device = device)\n",
        "        labels = labels.to(device = device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "print(f'Accuracy of the model on the validation images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b8rZsYccV0qX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "transfer_vgg.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "851433d38881c439cd1aa4ab1f9a2958ccad8ff830098145c1b18d13f5b5af71"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}