{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YanghuiWu/MV-Hat/blob/main/transfer_vgg.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_DdGGkYDXql",
        "outputId": "2b4df1db-cf10-4294-9049-1dabcc294d1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive/; to attempt to forcibly remount, call drive.mount(\"/content/gdrive/\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/Hats/FinalData\n",
            "\u001b[0m\u001b[01;34mData_Full\u001b[0m/     HumanOnly.csv           vgg16_hats_only.pt\n",
            "Data_Full.csv  lenet_hats.pt           vgg16_hats.pt\n",
            "\u001b[01;34mHatsOnly\u001b[0m/      pytorch_dataset.py      vgg16_human_imagenet.pt\n",
            "HatsOnly.csv   ReadMe.txt              vgg16_human_only.pt\n",
            "\u001b[01;34mHumanOnly\u001b[0m/     vgg16_hats_imagenet.pt  vgg16_imagenet.pt\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')\n",
        "%cd /content/gdrive/My Drive/Colab Notebooks/Hats/FinalData/\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "959GWP1VDJ-2"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import ssl\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from tqdm.notebook import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader\n",
        "#from pytorch_dataset import HatsDataset\n",
        "import torch.optim as optim\n",
        "\n",
        "# for pretrained model\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJjmixByD42m"
      },
      "outputs": [],
      "source": [
        "# for data prep\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "from skimage import io\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-UC4HTUDx4d"
      },
      "outputs": [],
      "source": [
        "class HatsDataset(Dataset):\n",
        "    def __init__(self, csv_file, root_dir,transform=None):\n",
        "        self.annotations = pd.read_csv(csv_file)\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.annotations)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        img_path = os.path.join(self.root_dir,self.annotations.iloc[index,0])\n",
        "        image = io.imread(img_path)\n",
        "        y_label = torch.tensor(int(self.annotations.iloc[index,1]))\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return (image,y_label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVEjlIv0DJ-4"
      },
      "outputs": [],
      "source": [
        "in_channel = 3\n",
        "num_class = 15\n",
        "learning_rate = 1e-3\n",
        "batch_size = 16\n",
        "num_epochs = 50\n",
        "\n",
        "# Prepare Dataset\n",
        "# for transfer learning, images are resized to 224*224\n",
        "\n",
        "tf = transforms.Compose([transforms.ToPILImage(),transforms.Resize((224, 224)),transforms.ToTensor()])\n",
        "\n",
        "# tf = transforms.Compose([\n",
        "#     transforms.Resize((224, 224)),\n",
        "#     transforms.RandomHorizontalFlip(),\n",
        "#     transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.1, hue=0.1),\n",
        "#     transforms.RandomAffine(degrees=40, translate=None, scale=(1, 2), shear=15, resample=False, fillcolor=0),\n",
        "#     transforms.ToTensor(),\n",
        "#     transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "# ])\n",
        "\n",
        "\n",
        "\n",
        "mixset = HatsDataset(csv_file='Data_Full.csv', root_dir='Data_Full', transform = tf)  #8779\n",
        "hatset = HatsDataset(csv_file='HatsOnly.csv', root_dir='HatsOnly', transform = tf)  #7139\n",
        "humanset = HatsDataset(csv_file='HumanOnly.csv', root_dir='HumanOnly', transform = tf)\n",
        "\n",
        "# transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "\n",
        "\n",
        "mix_trainset, mix_testset = torch.utils.data.random_split(mixset, [int(0.8*len(mixset)), len(mixset) - int(0.8*len(mixset))])\n",
        "hat_trainset, hat_testset = torch.utils.data.random_split(hatset, [int(0.8*len(hatset)), len(hatset) - int(0.8*len(hatset))])\n",
        "human_trainset, human_testset = torch.utils.data.random_split(humanset, [int(0.8*len(humanset)), len(humanset) - int(0.8*len(humanset))])\n",
        "\n",
        "classes = ('baseballcap', 'BikeHelmet', 'BucketHat', 'CowboyHat',\n",
        "           'FeltHat', 'FireFighterHat', 'FlatCap', 'GraduationCap', 'Heaterhat', 'MilitaryHelmet',\n",
        "           'MotorCycle Helmet', 'Police Hat', 'SateftyHelmet', 'TopHat', 'beanie')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BPZ3wfrb6XfD"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### ONLY CHANGE THIS\n",
        "trainset = hat_trainset\n",
        "testset = hat_testset\n",
        "\n",
        "checkpoint = \"vgg16_imagenet.pt\"\n",
        "### TO TEST ON DIFFERENT DATASETS\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0G41c6tDJ-6"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# https://www.analyticsvidhya.com/blog/2021/06/transfer-learning-using-vgg16-in-pytorch/\n",
        "\n",
        "model = models.vgg16(pretrained=True)\n",
        "dropout = 0.5\n",
        "num_classes = 15\n",
        "\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Linear(512 * 7 * 7, 4096),\n",
        "    nn.ReLU(True),\n",
        "    nn.Dropout(p=dropout),\n",
        "    nn.Linear(4096, 4096),\n",
        "    nn.ReLU(True),\n",
        "    nn.Dropout(p=dropout),\n",
        "    nn.Linear(4096, num_classes),\n",
        ")\n",
        "\n",
        "model = model.to(device=device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rr9uvp423KT1",
        "outputId": "4712c6a0-2594-48be-9fa6-91f949ce9934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [-1, 512, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
            "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [-1, 512, 14, 14]               0\n",
            "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 4096]      16,781,312\n",
            "             ReLU-37                 [-1, 4096]               0\n",
            "          Dropout-38                 [-1, 4096]               0\n",
            "           Linear-39                   [-1, 15]          61,455\n",
            "================================================================\n",
            "Total params: 134,321,999\n",
            "Trainable params: 134,321,999\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 218.77\n",
            "Params size (MB): 512.40\n",
            "Estimated Total Size (MB): 731.75\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchsummary import summary\n",
        "summary(model, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5omeHcERDJ-7",
        "outputId": "f1c966cc-ad03-45de-b0b8-cd64dacba89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch: 1 loss: 2.044405899294952\n",
            "[Epoch: 2 loss: 0.939999429618611\n",
            "[Epoch: 3 loss: 0.5981742288468599\n",
            "[Epoch: 4 loss: 0.44586484924647485\n",
            "[Epoch: 5 loss: 0.33152419840003927\n",
            "[Epoch: 6 loss: 0.2348187307433254\n",
            "[Epoch: 7 loss: 0.17447819899120667\n",
            "[Epoch: 8 loss: 0.14429436659072564\n",
            "[Epoch: 9 loss: 0.10791423951056511\n",
            "[Epoch: 10 loss: 0.08868328535522357\n",
            "[Epoch: 11 loss: 0.07543620182604317\n",
            "[Epoch: 12 loss: 0.060421233328869006\n",
            "[Epoch: 13 loss: 0.0598003325945729\n",
            "[Epoch: 14 loss: 0.045380965514119624\n",
            "[Epoch: 15 loss: 0.0461012769768638\n",
            "[Epoch: 16 loss: 0.04481444042754824\n",
            "[Epoch: 17 loss: 0.04406188127385186\n",
            "[Epoch: 18 loss: 0.030288206299235204\n",
            "[Epoch: 19 loss: 0.03770183555171884\n",
            "[Epoch: 20 loss: 0.030238226839049042\n",
            "[Epoch: 21 loss: 0.030545508676006868\n",
            "[Epoch: 22 loss: 0.028603396561069815\n",
            "[Epoch: 23 loss: 0.029211722964710158\n",
            "[Epoch: 24 loss: 0.03288109142672243\n",
            "[Epoch: 25 loss: 0.026166840798987196\n",
            "[Epoch: 26 loss: 0.02450763868054149\n",
            "[Epoch: 27 loss: 0.022874048454239435\n",
            "[Epoch: 28 loss: 0.021101852252597142\n",
            "[Epoch: 29 loss: 0.022508385663652607\n",
            "[Epoch: 30 loss: 0.025306978829038564\n",
            "[Epoch: 31 loss: 0.02070396237450907\n",
            "[Epoch: 32 loss: 0.022901717030520047\n",
            "[Epoch: 33 loss: 0.01751081580264976\n",
            "[Epoch: 34 loss: 0.017350785460231628\n",
            "[Epoch: 35 loss: 0.01978041536500971\n",
            "[Epoch: 36 loss: 0.015976864675557655\n",
            "[Epoch: 37 loss: 0.021535928819533742\n",
            "[Epoch: 38 loss: 0.021271714040303064\n",
            "[Epoch: 39 loss: 0.018612230429650024\n",
            "[Epoch: 40 loss: 0.01583322819123186\n",
            "[Epoch: 41 loss: 0.01532281822774956\n",
            "[Epoch: 42 loss: 0.01805038440144534\n",
            "[Epoch: 43 loss: 0.01665598264519883\n",
            "[Epoch: 44 loss: 0.012406237346033928\n",
            "[Epoch: 45 loss: 0.014265688550185281\n",
            "[Epoch: 46 loss: 0.014024971174153035\n",
            "[Epoch: 47 loss: 0.015209922872885478\n",
            "[Epoch: 48 loss: 0.017613013510712774\n",
            "[Epoch: 49 loss: 0.012241135697263353\n",
            "[Epoch: 50 loss: 0.01424028428734119\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# Training\n",
        "model.train()\n",
        "losses = []\n",
        "for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    running_loss = 0.0\n",
        "    for data in trainloader:\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "\n",
        "        inputs = inputs.to(device=device)\n",
        "        labels = labels.to(device=device)\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)    \n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    # print loss every epoch\n",
        "    print(f'[Epoch: {epoch + 1} loss: {running_loss / len(trainloader)}')\n",
        "    losses.append(running_loss / len(trainloader))\n",
        "    running_loss = 0.0\n",
        "\n",
        "print('Finished Training')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "Q6eOwmvRDuAt",
        "outputId": "9a70a2a8-8986-4abf-c924-29828beca7c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f4ce1dc47d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "torch.save(model.state_dict(), checkpoint)\n",
        "plt.plot(losses)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hzCcmILPDJ-8",
        "outputId": "692154db-0da1-4200-dd0c-2e4851a5dc62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the model on the validation images: 87 %\n"
          ]
        }
      ],
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "model.eval() # Turn to evaluation mode to ignore dropout\n",
        "\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        images, labels = data\n",
        "        # images = images.to('cpu')\n",
        "        # labels = labels.to('cpu')\n",
        "        images = images.to(device = device)\n",
        "        labels = labels.to(device = device)\n",
        "        # calculate outputs by running images through the network\n",
        "        outputs = model(images)\n",
        "        # the class with the highest energy is what we choose as prediction\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "print(f'Accuracy of the model on the validation images: {100 * correct // total} %')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "b8rZsYccV0qX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "name": "transfer_vgg.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "851433d38881c439cd1aa4ab1f9a2958ccad8ff830098145c1b18d13f5b5af71"
    },
    "kernelspec": {
      "display_name": "Python 3.9.12 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}