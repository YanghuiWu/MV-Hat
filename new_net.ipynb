{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision import datasets, transforms as trans\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_dataset import HatsDataset\n",
    "from tqdm.notebook import tqdm"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'Checkpoints/Res50 16B 40eP HatsOnly.pt'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_channel = 3\n",
    "num_class = 15\n",
    "learning_rate = 1e-4\n",
    "batch_size = 16\n",
    "num_epochs = 50\n",
    "\n",
    "reload = \"\"\n",
    "'Checkpoints/Res50 16B 40eP HatsOnly.pt'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1639\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# transform = trans.Compose(\n",
    "#     [trans.Resize(256), trans.CenterCrop(224), trans.PILToTensor(), trans.ConvertImageDtype(torch.float)])\n",
    "# dataset = datasets.ImageNet(\".\", split=\"train\", transform=transform)\n",
    "transform = trans.Compose([\n",
    "    trans.ToTensor(),\n",
    "    trans.RandomCrop(256, padding=3, padding_mode='constant'),\n",
    "    trans.RandomHorizontalFlip(),\n",
    "\n",
    "    trans.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "subject = 'HumanOnly'\n",
    "dataset = HatsDataset(csv_file='FinalData/' + subject + '.csv',\n",
    "                      root_dir='FinalData/' + subject,\n",
    "                      transform=transform)  #8778\n",
    "\n",
    "print(len(dataset))\n",
    "\n",
    "# transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "divider = round(len(dataset) * 0.8)\n",
    "train_set, test_set = torch.utils.data.random_split(dataset, [divider, len(dataset) - divider])\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "refresh_rate = round(divider / batch_size / 4)\n",
    "\n",
    "classes = ('baseballcap', 'BikeHelmet', 'BucketHat', 'CowboyHat',\n",
    "           'FeltHat', 'FireFighterHat', 'FlatCap', 'GraduationCap', 'Heaterhat', 'MilitaryHelmet',\n",
    "           'MotorCycle Helmet', 'Police Hat', 'SateftyHelmet', 'TopHat', 'beanie')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# net = resnet50()\n",
    "model_name = \"Trans_\" + \"resnet50\"\n",
    "model = models.resnet50(pretrained=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "losses = []\n",
    "model\n",
    "model.fc = nn.Linear(model.fc.in_features, num_class)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "if reload:\n",
    "    path = reload\n",
    "    checkpoint = torch.load(path)\n",
    "\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    ep = checkpoint['epoch']\n",
    "    losses = checkpoint['losses']\n",
    "\n",
    "    # train_set = checkpoint['train_set']\n",
    "    # test_set = checkpoint['test_set']\n",
    "    # train_loader = checkpoint['train_loader']\n",
    "    # test_loader = checkpoint['test_loader']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "ResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (3): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (4): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (5): Bottleneck(\n      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): Bottleneck(\n      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (downsample): Sequential(\n        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n    (2): Bottleneck(\n      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=2048, out_features=15, bias=True)\n)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://androidkt.com/modify-pre-train-pytorch-model-for-finetuning-and-feature-extraction/\n",
    "# VGG uses https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/blob/master/pytorch_object_detection/faster_rcnn/backbone/vgg_model.py\n",
    "# Transfer Learning https://www.analyticsvidhya.com/blog/2021/06/transfer-learning-using-vgg16-in-pytorch/\n",
    "model.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "  0%|          | 0/50 [00:00<?, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8e4a1e57b36445b9b916d3206f0fba33"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.   20-loss:2.705 ||   40-loss:2.661 ||   60-loss:2.670 ||   80-loss:2.659 || Lasted 0m 36s, Remaining 29.1m\n",
      " 2.   20-loss:2.621 ||   40-loss:2.610 ||   60-loss:2.607 ||   80-loss:2.593 || Lasted 0m 33s, Remaining 26.4m\n",
      " 3.   20-loss:2.567 ||   40-loss:2.531 ||   60-loss:2.543 ||   80-loss:2.518 || Lasted 0m 33s, Remaining 25.9m\n",
      " 4.   20-loss:2.484 ||   40-loss:2.466 ||   60-loss:2.460 ||   80-loss:2.453 || Lasted 0m 33s, Remaining 25.3m\n",
      " 5.   20-loss:2.424 ||   40-loss:2.429 ||   60-loss:2.388 ||   80-loss:2.355 || Lasted 0m 33s, Remaining 24.8m\n",
      " 6.   20-loss:2.352 ||   40-loss:2.295 ||   60-loss:2.313 ||   80-loss:2.304 || Lasted 0m 33s, Remaining 24.2m\n",
      " 7.   20-loss:2.242 ||   40-loss:2.241 ||   60-loss:2.217 ||   80-loss:2.243 || Lasted 0m 33s, Remaining 23.7m\n",
      " 8.   20-loss:2.213 ||   40-loss:2.148 ||   60-loss:2.156 ||   80-loss:2.117 || Lasted 0m 33s, Remaining 23.1m\n",
      " 9.   20-loss:2.072 ||   40-loss:2.052 ||   60-loss:2.109 ||   80-loss:2.074 || Lasted 0m 33s, Remaining 22.6m\n",
      "10.   20-loss:2.027 ||   40-loss:2.021 ||   60-loss:1.967 ||   80-loss:1.962 || Lasted 0m 33s, Remaining 22.0m\n",
      "11.   20-loss:1.899 ||   40-loss:1.920 ||   60-loss:1.905 ||   80-loss:1.906 || Lasted 0m 33s, Remaining 21.5m\n",
      "12.   20-loss:1.781 ||   40-loss:1.877 ||   60-loss:1.774 ||   80-loss:1.823 || Lasted 0m 33s, Remaining 21.1m\n",
      "13.   20-loss:1.774 ||   40-loss:1.714 ||   60-loss:1.784 ||   80-loss:1.714 || Lasted 0m 33s, Remaining 20.5m\n",
      "14.   20-loss:1.696 ||   40-loss:1.669 ||   60-loss:1.665 ||   80-loss:1.621 || Lasted 0m 33s, Remaining 20.0m\n",
      "15.   20-loss:1.610 ||   40-loss:1.601 ||   60-loss:1.567 ||   80-loss:1.595 || Lasted 0m 33s, Remaining 19.3m\n",
      "16.   20-loss:1.553 ||   40-loss:1.547 ||   60-loss:1.534 ||   80-loss:1.483 || Lasted 0m 33s, Remaining 18.7m\n",
      "17.   20-loss:1.534 ||   40-loss:1.407 ||   60-loss:1.509 ||   80-loss:1.439 || Lasted 0m 33s, Remaining 18.2m\n",
      "18.   20-loss:1.423 ||   40-loss:1.378 ||   60-loss:1.431 ||   80-loss:1.372 || Lasted 0m 33s, Remaining 17.6m\n",
      "19.   20-loss:1.393 ||   40-loss:1.306 ||   60-loss:1.392 ||   80-loss:1.308 || Lasted 0m 33s, Remaining 17.1m\n",
      "20.   20-loss:1.298 ||   40-loss:1.322 ||   60-loss:1.319 ||   80-loss:1.303 || Lasted 0m 33s, Remaining 16.5m\n",
      "21.   20-loss:1.249 ||   40-loss:1.308 ||   60-loss:1.207 ||   80-loss:1.317 || Lasted 0m 33s, Remaining 16.0m\n",
      "22.   20-loss:1.261 ||   40-loss:1.197 ||   60-loss:1.292 ||   80-loss:1.175 || Lasted 0m 33s, Remaining 15.4m\n",
      "23.   20-loss:1.191 ||   40-loss:1.232 ||   60-loss:1.155 ||   80-loss:1.193 || Lasted 0m 33s, Remaining 14.9m\n",
      "24.   20-loss:1.092 ||   40-loss:1.244 ||   60-loss:1.124 ||   80-loss:1.188 || Lasted 0m 33s, Remaining 14.3m\n",
      "25.   20-loss:1.091 ||   40-loss:1.100 ||   60-loss:1.132 ||   80-loss:1.155 || Lasted 0m 33s, Remaining 13.8m\n",
      "26.   20-loss:1.082 ||   40-loss:1.050 ||   60-loss:1.090 ||   80-loss:1.100 || Lasted 0m 33s, Remaining 13.2m\n",
      "27.   20-loss:1.034 ||   40-loss:1.079 ||   60-loss:1.107 ||   80-loss:1.013 || Lasted 0m 33s, Remaining 12.8m\n",
      "28.   20-loss:1.077 ||   40-loss:0.962 ||   60-loss:0.993 ||   80-loss:1.040 || Lasted 0m 33s, Remaining 12.1m\n",
      "29.   20-loss:0.947 ||   40-loss:0.959 ||   60-loss:1.028 ||   80-loss:1.005 || Lasted 0m 33s, Remaining 11.5m\n",
      "30.   20-loss:0.960 ||   40-loss:1.009 ||   60-loss:0.968 ||   80-loss:0.984 || Lasted 0m 33s, Remaining 11.0m\n",
      "31.   20-loss:0.986 ||   40-loss:0.911 ||   60-loss:0.951 ||   80-loss:0.903 || Lasted 0m 33s, Remaining 10.4m\n",
      "32.   20-loss:0.947 ||   40-loss:0.866 ||   60-loss:0.884 ||   80-loss:0.896 || Lasted 0m 33s, Remaining 9.9m\n",
      "33.   20-loss:0.903 ||   40-loss:0.908 ||   60-loss:0.855 ||   80-loss:0.863 || Lasted 0m 33s, Remaining 9.4m\n",
      "34.   20-loss:0.891 ||   40-loss:0.828 ||   60-loss:0.858 ||   80-loss:0.883 || Lasted 0m 33s, Remaining 8.8m\n",
      "35.   20-loss:0.845 ||   40-loss:0.842 ||   60-loss:0.799 ||   80-loss:0.791 || Lasted 0m 33s, Remaining 8.3m\n",
      "36.   20-loss:0.807 ||   40-loss:0.839 ||   60-loss:0.809 ||   80-loss:0.842 || Lasted 0m 33s, Remaining 7.7m\n",
      "37.   20-loss:0.744 ||   40-loss:0.790 ||   60-loss:0.837 ||   80-loss:0.803 || Lasted 0m 33s, Remaining 7.1m\n",
      "38.   20-loss:0.675 ||   40-loss:0.808 ||   60-loss:0.749 ||   80-loss:0.783 || Lasted 0m 33s, Remaining 6.6m\n",
      "39.   20-loss:0.770 ||   40-loss:0.723 ||   60-loss:0.757 ||   80-loss:0.716 || Lasted 0m 33s, Remaining 6.0m\n",
      "40.   20-loss:0.747 ||   40-loss:0.729 ||   60-loss:0.745 ||   80-loss:0.721 || Lasted 0m 33s, Remaining 5.6m\n",
      "41.   20-loss:0.738 ||   40-loss:0.768 ||   60-loss:0.697 ||   80-loss:0.656 || Lasted 0m 33s, Remaining 4.9m\n",
      "42.   20-loss:0.761 ||   40-loss:0.696 ||   60-loss:0.628 ||   80-loss:0.697 || Lasted 0m 33s, Remaining 4.4m\n",
      "43.   20-loss:0.701 ||   40-loss:0.668 ||   60-loss:0.651 ||   80-loss:0.626 || Lasted 0m 33s, Remaining 3.9m\n",
      "44.   20-loss:0.613 ||   40-loss:0.667 ||   60-loss:0.675 ||   80-loss:0.613 || Lasted 0m 33s, Remaining 3.3m\n",
      "45.   20-loss:0.714 ||   40-loss:0.614 ||   60-loss:0.622 ||   80-loss:0.643 || Lasted 0m 33s, Remaining 2.7m\n",
      "46.   20-loss:0.641 ||   40-loss:0.616 ||   60-loss:0.607 ||   80-loss:0.645 || Lasted 0m 33s, Remaining 2.2m\n",
      "47.   20-loss:0.588 ||   40-loss:0.618 ||   60-loss:0.621 ||   80-loss:0.594 || Lasted 0m 33s, Remaining 1.7m\n",
      "48.   20-loss:0.511 ||   40-loss:0.629 ||   60-loss:0.579 ||   80-loss:0.627 || Lasted 0m 33s, Remaining 1.1m\n",
      "49.   20-loss:0.608 ||   40-loss:0.559 ||   60-loss:0.544 ||   80-loss:0.577 || Lasted 0m 33s, Remaining 0.5m\n",
      "50.   20-loss:0.548 ||   40-loss:0.586 ||   60-loss:0.547 ||   80-loss:0.563 || Lasted 0m 33s, Remaining 0.0m\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "text/plain": "[<matplotlib.lines.Line2D at 0x2421e4ae8e0>]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for epoch in tqdm(range(num_epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "    since = time.time()\n",
    "    running_loss = 0.0\n",
    "    loss_sum = 0.0\n",
    "    print(f'{epoch + 1:2d}.', end=\" \")\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % refresh_rate == refresh_rate - 1:  # print every 2000 mini-batches\n",
    "            print(f'{i + 1:4d}-loss:{running_loss / refresh_rate:.3f}', end=\" ||\")\n",
    "            loss_sum += running_loss\n",
    "            running_loss = 0.0\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Lasted {:.0f}m {:.0f}s, Remaining {:.1f}m'.format(time_elapsed // 60, time_elapsed % 60,\n",
    "                                                             time_elapsed / 60 * (num_epochs - epoch - 1)))\n",
    "    losses.append(loss_sum)\n",
    "\n",
    "print('Finished Training')\n",
    "plt.plot(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7138\n"
     ]
    }
   ],
   "source": [
    "test = False\n",
    "if test:\n",
    "    subject = 'HatsOnly'\n",
    "    dataset = HatsDataset(csv_file='FinalData/' + subject + '.csv',\n",
    "                          root_dir='FinalData/' + subject,\n",
    "                          transform=transform)  #8778\n",
    "\n",
    "    print(len(dataset))\n",
    "\n",
    "    # transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "    divider = round(len(dataset) * 0.8)\n",
    "    train_set, test_set = torch.utils.data.random_split(dataset, [divider, len(dataset) - divider])\n",
    "    test_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 batches, 50 Epochs\n",
      "Accuracy of the network on the validation images: 53 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # images = images.cuda()\n",
    "        # labels = labels.cuda()\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = model(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'{batch_size} batches, {num_epochs} Epochs')\n",
    "print(f'Accuracy of the network on the validation images: {100 * correct // total} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "torch.save({\n",
    "    'epoch': len(losses),\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'losses': losses,\n",
    "    'train_set': train_set,\n",
    "    'test_set': test_set,\n",
    "    'train_loader': train_loader,\n",
    "    'test_loader': test_loader\n",
    "}, 'Checkpoints/' + model_name + \" \" + str(batch_size) + 'B ' + str(len(losses)) + 'eP ' + subject + '.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}