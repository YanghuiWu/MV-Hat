{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import ssl\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from pytorch_dataset import HatsDataset\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "in_channel = 3\n",
    "num_class = 15\n",
    "learning_rate = 1e-3\n",
    "batch_size = 16\n",
    "num_epochs = 20\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.RandomCrop(256, padding=3, padding_mode='constant'),\n",
    "     transforms.RandomHorizontalFlip(),\n",
    "     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "subject = 'Dataset_Full'\n",
    "\n",
    "dataset = HatsDataset(csv_file='FinalData/' + subject + '.csv',\n",
    "                      root_dir='FinalData/' + subject,\n",
    "                      transform=transform)  #8778\n",
    "\n",
    "print(len(dataset))\n",
    "\n",
    "# transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "divider = round(len(dataset) * 0.8)\n",
    "\n",
    "trainset, testset = torch.utils.data.random_split(dataset, [divider, len(dataset) - divider])\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('baseballcap', 'BikeHelmet', 'BucketHat', 'CowboyHat',\n",
    "           'FeltHat', 'FireFighterHat', 'FlatCap', 'GraduationCap', 'Heaterhat', 'MilitaryHelmet',\n",
    "           'MotorCycle Helmet', 'Police Hat', 'SateftyHelmet', 'TopHat', 'beanie')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "refresh_rate = round(divider / batch_size /3)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    # img = img / 2 + 0.4     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(16, 7))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title('        '.join('%5s' % classes[labels[j]] for j in range(8)))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "imshow(torchvision.utils.make_grid(images))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(\n",
    "            self, in_channels, intermediate_channels, identity_downsample=None, stride=1\n",
    "    ):\n",
    "        super(Block, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Conv2d(\n",
    "            in_channels, intermediate_channels, kernel_size=1, stride=1, padding=0, bias=False\n",
    "        )\n",
    "        self.bn1 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv2 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels,\n",
    "            kernel_size=3,\n",
    "            stride=stride,\n",
    "            padding=1,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn2 = nn.BatchNorm2d(intermediate_channels)\n",
    "        self.conv3 = nn.Conv2d(\n",
    "            intermediate_channels,\n",
    "            intermediate_channels * self.expansion,\n",
    "            kernel_size=1,\n",
    "            stride=1,\n",
    "            padding=0,\n",
    "            bias=False\n",
    "        )\n",
    "        self.bn3 = nn.BatchNorm2d(intermediate_channels * self.expansion)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.identity_downsample = identity_downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        if self.identity_downsample is not None:\n",
    "            identity = self.identity_downsample(identity)\n",
    "\n",
    "        x += identity\n",
    "        x = self.relu(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(in_channel, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self._make_layer(\n",
    "            block, layers[0], intermediate_channels=64, stride=1\n",
    "        )\n",
    "        self.layer2 = self._make_layer(\n",
    "            block, layers[1], intermediate_channels=128, stride=2\n",
    "        )\n",
    "        self.layer3 = self._make_layer(\n",
    "            block, layers[2], intermediate_channels=256, stride=2\n",
    "        )\n",
    "        self.layer4 = self._make_layer(\n",
    "            block, layers[3], intermediate_channels=512, stride=2\n",
    "        )\n",
    "\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * 4, num_class)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, num_residual_blocks, intermediate_channels, stride):\n",
    "        identity_down_sample = None\n",
    "        layers = []\n",
    "\n",
    "        if stride != 1 or self.in_channels != intermediate_channels * 4:\n",
    "            identity_down_sample = nn.Sequential(\n",
    "                nn.Conv2d(\n",
    "                    self.in_channels,\n",
    "                    intermediate_channels * 4,\n",
    "                    kernel_size=1,\n",
    "                    stride=stride,\n",
    "                    bias=False\n",
    "                ),\n",
    "                nn.BatchNorm2d(intermediate_channels * 4),\n",
    "            )\n",
    "\n",
    "        layers.append(\n",
    "            block(self.in_channels, intermediate_channels, identity_down_sample, stride)\n",
    "        )\n",
    "\n",
    "        # The expansion size is always 4 for ResNet 50,101,152\n",
    "        self.in_channels = intermediate_channels * 4\n",
    "\n",
    "        # first resnet layer: 256 will be mapped to 64 as intermediate layer,\n",
    "        # then finally back to 256. no NEED identity down sample SO stride = 1,\n",
    "        # and also same channels #.\n",
    "        for j in range(num_residual_blocks - 1):\n",
    "            layers.append(block(self.in_channels, intermediate_channels))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "    return ResNet(Block, [3, 4, 6, 3])\n",
    "\n",
    "\n",
    "def resnet101():\n",
    "    return ResNet(Block, [3, 4, 23, 3])\n",
    "\n",
    "\n",
    "def resnet152():\n",
    "    return ResNet(Block, [3, 8, 36, 3])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def conv2d_Moduel(in_channel, out, K_sz=3, pad=1, st=1):\n",
    "    hidden_layer = [nn.Conv2d(in_channel, out, kernel_size=K_sz, padding=pad, stride=st),\n",
    "                    nn.BatchNorm2d(out),\n",
    "                    nn.LeakyReLU(inplace=True)]\n",
    "    return nn.Sequential(*hidden_layer)\n",
    "\n",
    "\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, connect=True):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.connect = connect\n",
    "        self.conv1 = nn.Sequential(conv2d_Moduel(in_channels, out_channels),\n",
    "                                   nn.MaxPool2d(kernel_size=2, stride=2),  #downsize\n",
    "                                   conv2d_Moduel(out_channels, out_channels))\n",
    "        self.conv2 = nn.Sequential(conv2d_Moduel(out_channels, out_channels),\n",
    "                                   conv2d_Moduel(out_channels, out_channels))\n",
    "        self.relu = nn.LeakyReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.connect:\n",
    "            y = self.conv1(x)\n",
    "        else:\n",
    "            y = self.conv2(x)\n",
    "            y = y + x\n",
    "        z = self.conv2(y)\n",
    "        z = z + y\n",
    "        z = self.relu(z)\n",
    "        return z\n",
    "\n",
    "\n",
    "class ResNet18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet18, self).__init__()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=1)\n",
    "        self.conv1 = conv2d_Moduel(3, 64, K_sz=7, pad=3, st=2)\n",
    "        self.conv2 = ResNetBlock(64, 64, connect=False)\n",
    "        self.conv3 = ResNetBlock(64, 128)\n",
    "        self.conv4 = ResNetBlock(128, 256)\n",
    "        self.conv5 = ResNetBlock(256, 512)\n",
    "        self.classifier = nn.Sequential(nn.MaxPool2d(4),\n",
    "                                        nn.Flatten(),\n",
    "                                        nn.Linear(512 * 4 * 4, 256),\n",
    "                                        nn.LeakyReLU(),\n",
    "                                        nn.Linear(256, 128),\n",
    "                                        nn.LeakyReLU(),\n",
    "                                        nn.Linear(128, 15)\n",
    "                                        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)  #layer 1\n",
    "        x = self.conv2(x)  #layer 2,3,4,5\n",
    "        x = self.conv3(x)  #layer 6,7,8,9\n",
    "        x = self.conv4(x)  #layer 10,11,12,13\n",
    "        x = self.conv5(x)  #layer 14,15,16,17\n",
    "        x = self.classifier(x)  #(18)\n",
    "        return x\n",
    "        #y = self.fc4(x)\n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(244 * 244, 1200)\n",
    "        self.fc2 = nn.Linear(1200, 84)\n",
    "        self.fc3 = nn.Linear(84, 15)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = torch.flatten(x, 1)  # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "net = resnet50()\n",
    "net.to(device)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "losses = []"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "reload = False\n",
    "if reload:\n",
    "    path = 'Checkpoints/Res50 16B 40eP HatsOnly.pt'\n",
    "    checkpoint = torch.load(path)\n",
    "\n",
    "    net.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    ep = checkpoint['epoch']\n",
    "    losses = checkpoint['loss']\n",
    "\n",
    "    trainset = checkpoint['trainset']\n",
    "    testset = checkpoint['testset']\n",
    "    trainloader = checkpoint['trainloader']\n",
    "    testloader = checkpoint['testloader']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(num_epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "    since = time.time()\n",
    "    running_loss = 0.0\n",
    "    loss_sum = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        # with torch.cuda.amp.autocast():\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % refresh_rate == refresh_rate - 1:  # print every 2000 mini-batches\n",
    "            print(f'[{epoch + 1:2d}, {i + 1:4d}]loss:{running_loss / refresh_rate:.3f}', end=\" || \")\n",
    "            loss_sum += running_loss\n",
    "            running_loss = 0.0\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Lasted {:.0f}m {:.0f}s, Remaining {:.1f}m'.format(time_elapsed // 60, time_elapsed % 60,\n",
    "                                                             time_elapsed / 60 * (num_epochs - epoch - 1)))\n",
    "    losses.append(loss_sum)\n",
    "\n",
    "print('Finished Training')\n",
    "plt.plot(losses)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# YOUR CODE HERE\n",
    "# raise NotImplementedError()\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # images = images.cuda()\n",
    "        # labels = labels.cuda()\n",
    "        # calculate outputs by running images through the network\n",
    "        outputs = net(images)\n",
    "        # the class with the highest energy is what we choose as prediction\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'{batch_size} batches, {num_epochs} Epochs')\n",
    "print(f'Accuracy of the network on the validation images: {100 * correct // total} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# torch.cuda.is_available\n",
    "# torch.save(net.state_dict(), PATH)\n",
    "# epoch = 40\n",
    "torch.save({\n",
    "    'epoch': epoch,\n",
    "    'model_state_dict': net.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'losses': losses,\n",
    "    'trainset': trainset,\n",
    "    'testset': testset,\n",
    "    'trainloader': trainloader,\n",
    "    'testloader': testloader\n",
    "}, 'Checkpoints/Res50 ' + str(batch_size) + 'B ' + str(num_epochs+20) + 'eP ' + subject + '.pt')\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}